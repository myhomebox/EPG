import os
import re
import json
import time
import random
import argparse
import requests
import datetime
import pytz
from bs4 import BeautifulSoup
from xml.etree import ElementTree as ET
from xml.dom import minidom

# å…¨å±€æ™‚å€è¨­ç½®
TAIPEI_TZ = pytz.timezone('Asia/Taipei')
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def parse_channel_list():
    """è§£æé »é“åˆ—è¡¨æª”æ¡ˆå…§å®¹"""
    channels = []
    channel_list = [
        "ä¸­å¤©æ–°èå° ==> 4gtv-4gtv009",
        "å°è¦– ==> 4gtv-4gtv066",
        "ä¸­è¦– ==> 4gtv-4gtv040",
        "è¯è¦– ==> 4gtv-4gtv041",
        "å°è¦–æ–°è ==> 4gtv-4gtv051",
        "è¯è¦–æ–°è ==> 4gtv-4gtv052",
        "ä¸­è¦–æ–°è ==> 4gtv-4gtv074",
        "åœ‹æœƒé »é“1å° ==> 4gtv-4gtv084",
        "åœ‹æœƒé »é“2å° ==> 4gtv-4gtv085",
        "äºæ´²æ—…éŠå° ==> 4gtv-4gtv076",
        "æ±æ£®è³¼ç‰©1å° ==> 4gtv-4gtv102",
        "æ±æ£®è³¼ç‰©2å° ==> 4gtv-4gtv103",
        "ç¬¬1å•†æ¥­å° ==> 4gtv-4gtv104",
        "å¯°å®‡æ–°èå°ç£å° ==> 4gtv-4gtv156",
        "å¯°å®‡è²¡ç¶“å° ==> 4gtv-4gtv158",
        "å¥½æ¶ˆæ¯ ==> litv-ftv16",
        "å¥½æ¶ˆæ¯2å° ==> litv-ftv17",
        "é¾è¯å¡é€šå° ==> litv-longturn01",
        "é¾è¯æ´‹ç‰‡å° ==> litv-longturn02",
        "é¾è¯é›»å½±å° ==> litv-longturn03",
        "é¾è¯æ—¥éŸ“å° ==> litv-longturn11",
        "é¾è¯å¶åƒå° ==> litv-longturn12",
        "å¯°å®‡æ–°èå° ==> litv-longturn14",
        "é¾è¯æˆ²åŠ‡å° ==> litv-longturn18",
        "SmartçŸ¥è­˜å° ==> litv-longturn19",
        "ELTVç”Ÿæ´»è‹±èªå° ==> litv-longturn20",
        "é¾è¯ç¶“å…¸å° ==> litv-longturn21",
        "å°ç£æˆ²åŠ‡å° ==> litv-longturn22",
        "ä¸‰ç«‹æ–°èiNEWS ==> iNEWS",
        "å€ªçæ’­æ–°è ==> nnews-zh",
        "å€ªçå ±æ°£è±¡ ==> nnews-wf",
        "å€ªçè¶Šå—èªæ–°è ==> nnews-vn"
    ]
    
    for line in channel_list:
        if '==>' in line:
            parts = line.split('==>')
            if len(parts) == 2:
                channel_name = parts[0].strip()
                channel_id = parts[1].strip()
                channels.append((channel_name, channel_id))
    return channels

def fetch_epg_data(channel_id, max_retries=3):
    """ç²å–æŒ‡å®šé »é“çš„EPGæ•¸æ“š"""
    url = f"https://www.ofiii.com/channel/watch/{channel_id}"
    
    for attempt in range(max_retries):
        try:
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            script_tag = soup.find('script', id='__NEXT_DATA__')
            
            if script_tag:
                json_data = json.loads(script_tag.string)
                return json_data
            else:
                print(f"âŒ æœªæ‰¾åˆ°__NEXT_DATA__æ¨™ç°½: {channel_id}")
                return None
                
        except (requests.RequestException, json.JSONDecodeError) as e:
            wait_time = random.uniform(1, 3) * (attempt + 1)
            print(f"âš ï¸ è«‹æ±‚å¤±æ•— (å˜—è©¦ {attempt+1}/{max_retries}), ç­‰å¾… {wait_time:.2f}ç§’: {str(e)}")
            time.sleep(wait_time)
    
    print(f"âŒ ç„¡æ³•ç²å–EPGæ•¸æ“š: {channel_id}")
    return None

def parse_epg_data(json_data, channel_name):
    """è§£æEPG JSONæ•¸æ“š"""
    if not json_data:
        return []
    
    programs = []
    try:
        schedule = json_data['props']['pageProps']['channel']['Schedule']
        
        for item in schedule:
            # è§£æé–‹å§‹æ™‚é–“ (UTCæ™‚é–“)
            start_utc = datetime.datetime.strptime(
                item['AirDateTime'], "%Y-%m-%dT%H:%M:%SZ"
            ).replace(tzinfo=pytz.utc)
            
            # è½‰æ›ç‚ºå°åŒ—æ™‚å€
            start_taipei = start_utc.astimezone(TAIPEI_TZ)
            
            # è¨ˆç®—çµæŸæ™‚é–“
            duration = datetime.timedelta(seconds=item['Duration'])
            end_taipei = start_taipei + duration
            
            program_info = item.get('program', {})
            
            programs.append({
                "channelName": channel_name,
                "programName": program_info.get('Title', 'æœªçŸ¥ç¯€ç›®'),
                "description": program_info.get('Description', ''),
                "subtitle": program_info.get('SubTitle', ''),
                "start": start_taipei,
                "end": end_taipei
            })
            
    except (KeyError, TypeError, ValueError) as e:
        print(f"âŒ è§£æEPGæ•¸æ“šå¤±æ•—: {str(e)}")
    
    return programs

def get_ofiii_epg():
    """ç²å–OFIIIçš„EPGæ•¸æ“š"""
    print("="*50)
    print("é–‹å§‹ç²å–OFIII EPGæ•¸æ“š")
    print("="*50)
    
    # ç²å–é »é“åˆ—è¡¨
    channels_info = parse_channel_list()
    if not channels_info:
        print("âŒ ç„¡æ³•è§£æé »é“åˆ—è¡¨")
        return [], []
    
    all_channels = []
    all_programs = []
    
    # éæ­·æ‰€æœ‰é »é“
    for idx, (channel_name, channel_id) in enumerate(channels_info):
        print(f"\nè™•ç†é »é“ [{idx+1}/{len(channels_info)}]: {channel_name} ({channel_id})")
        
        # ç²å–EPGæ•¸æ“š
        json_data = fetch_epg_data(channel_id)
        if not json_data:
            continue
            
        # è§£æç¯€ç›®æ•¸æ“š
        programs = parse_epg_data(json_data, channel_name)
        
        # æ·»åŠ é »é“ä¿¡æ¯
        try:
            channel_data = json_data['props']['pageProps']['channel']
            logo = channel_data.get('picture', '')
            if not logo:
                logo = json_data['props']['pageProps']['introduction'].get('image', '')
            
            # ç¢ºä¿logoæ˜¯å®Œæ•´URL
            if logo and not logo.startswith('http'):
                logo = f"https://p-cdnstatic.svc.litv.tv/pics/{logo}"
            
            all_channels.append({
                "name": channel_name,
                "channelName": channel_name,
                "id": channel_id,
                "url": f"https://www.ofiii.com/channel/watch/{channel_id}",
                "source": "ofiii",
                "logo": logo,
                "desc": json_data['props']['pageProps']['introduction'].get('description', '')
            })
        except (KeyError, TypeError) as e:
            print(f"âŒ è§£æé »é“ä¿¡æ¯å¤±æ•—: {channel_name}, {str(e)}")
            continue
            
        # æ·»åŠ ç¯€ç›®æ•¸æ“š
        all_programs.extend(programs)
        
        # éš¨æ©Ÿå»¶é² (1-3ç§’)
        if idx < len(channels_info) - 1:
            delay = random.uniform(1, 3)
            print(f"â±ï¸ éš¨æ©Ÿå»¶é² {delay:.2f}ç§’")
            time.sleep(delay)
    
    # çµ±è¨ˆçµæœ
    print("\n" + "="*50)
    print(f"âœ… æˆåŠŸç²å– {len(all_channels)} å€‹é »é“")
    print(f"âœ… æˆåŠŸç²å– {len(all_programs)} å€‹ç¯€ç›®")
    
    # æŒ‰é »é“åç¨±åˆ†çµ„é¡¯ç¤ºç¯€ç›®æ•¸é‡
    channel_counts = {}
    for program in all_programs:
        channel_counts[program["channelName"]] = channel_counts.get(program["channelName"], 0) + 1
    
    for channel, count in channel_counts.items():
        print(f"ğŸ“º é »é“ {channel}: {count} å€‹ç¯€ç›®")
    
    print("="*50)
    return all_channels, all_programs

def generate_xmltv(channels, programs, output_file="ofiii.xml"):
    """ç”ŸæˆXMLTVæ ¼å¼çš„EPGæ•¸æ“š"""
    print(f"\nç”ŸæˆXMLTVæª”æ¡ˆ: {output_file}")
    
    # å»ºç«‹XMLæ ¹å…ƒç´ 
    root = ET.Element("tv", generator="OFIII-EPG-Generator", source="www.ofiii.com")
    
    # æ·»åŠ é »é“ä¿¡æ¯
    for channel in channels:
        channel_elem = ET.SubElement(root, "channel", id=channel['id'])
        ET.SubElement(channel_elem, "display-name").text = channel['name']
        
        if channel['logo']:
            ET.SubElement(channel_elem, "icon", src=channel['logo'])
    
    # æ·»åŠ ç¯€ç›®ä¿¡æ¯
    for program in programs:
        # XMLTVè¦æ±‚é »é“IDä½œç‚ºå±¬æ€§
        channel_id = next((ch['id'] for ch in channels if ch['name'] == program['channelName']), None)
        if not channel_id:
            continue
            
        # æ ¼å¼åŒ–æ™‚é–“ (XMLTVæ ¼å¼: YYYYMMDDHHMMSS +TZ)
        start_time = program['start'].strftime('%Y%m%d%H%M%S %z')
        end_time = program['end'].strftime('%Y%m%d%H%M%S %z')
        
        # å»ºç«‹ç¯€ç›®å…ƒç´ 
        program_elem = ET.SubElement(
            root, 
            "programme", 
            start=start_time, 
            stop=end_time, 
            channel=channel_id
        )
        
        # æ·»åŠ ç¯€ç›®ä¿¡æ¯
        ET.SubElement(program_elem, "title", lang="zh").text = program['programName']
        
        if program.get('subtitle'):
            ET.SubElement(program_elem, "sub-title", lang="zh").text = program['subtitle']
        
        if program.get('description'):
            ET.SubElement(program_elem, "desc", lang="zh").text = program['description']
    
    # ç”ŸæˆXMLå­—ç¬¦ä¸²
    xml_str = ET.tostring(root, encoding='utf-8').decode('utf-8')
    
    # ç¾åŒ–XMLæ ¼å¼
    parsed = minidom.parseString(xml_str)
    pretty_xml = parsed.toprettyxml(indent="  ", encoding='utf-8')
    
    # å„²å­˜åˆ°æª”æ¡ˆ
    with open(output_file, 'wb') as f:
        f.write(pretty_xml)
    
    print(f"âœ… XMLTVæª”æ¡ˆå·²ç”Ÿæˆ: {output_file}")
    print(f"ğŸ“º é »é“æ•¸: {len(channels)}")
    print(f"ğŸ“º ç¯€ç›®æ•¸: {len(programs)}")
    print(f"ğŸ’¾ æª”æ¡ˆå¤§å°: {os.path.getsize(output_file) / 1024:.2f} KB")

def main():
    """ä¸»å‡½æ•¸ï¼Œè™•ç†å‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(description='OFIII EPG ç”Ÿæˆå™¨')
    parser.add_argument('--output', type=str, default='output/ofiii.xml', 
                       help='è¼¸å‡ºXMLæª”æ¡ˆè·¯å¾‘ (é»˜èª: output/ofiii.xml)')
    
    args = parser.parse_args()
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_dir = os.path.dirname(args.output)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"å»ºç«‹è¼¸å‡ºç›®éŒ„: {output_dir}")
    
    # ç²å–EPGæ•¸æ“š
    channels, programs = get_ofiii_epg()
    
    # ç”ŸæˆXMLTVæª”æ¡ˆ
    generate_xmltv(channels, programs, args.output)

if __name__ == "__main__":
    main()
